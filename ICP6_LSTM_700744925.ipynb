{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoshanPoddaturi/Neural_Networks/blob/main/ICP6_LSTM_700744925.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tensorflow keras pandas matplotlib scikit-learn\n",
        "!pip install tensorflow==2.15.0 keras==2.15.0 pandas==2.0.3 matplotlib==3.9.1 scikit-learn==1.5.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HVc_yBzE4J_o",
        "outputId": "095c861c-69a4-4f73-f7e6-ad84230820dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.15.0\n",
            "Uninstalling tensorflow-2.15.0:\n",
            "  Successfully uninstalled tensorflow-2.15.0\n",
            "Found existing installation: keras 2.15.0\n",
            "Uninstalling keras-2.15.0:\n",
            "  Successfully uninstalled keras-2.15.0\n",
            "Found existing installation: pandas 2.0.3\n",
            "Uninstalling pandas-2.0.3:\n",
            "  Successfully uninstalled pandas-2.0.3\n",
            "Found existing installation: matplotlib 3.7.1\n",
            "Uninstalling matplotlib-3.7.1:\n",
            "  Successfully uninstalled matplotlib-3.7.1\n",
            "Found existing installation: scikit-learn 1.2.2\n",
            "Uninstalling scikit-learn-1.2.2:\n",
            "  Successfully uninstalled scikit-learn-1.2.2\n",
            "Collecting tensorflow==2.15.0\n",
            "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras==2.15.0\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==2.0.3\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.9.1\n",
            "  Downloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.5.1\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (3.1.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Installing collected packages: keras, scikit-learn, pandas, matplotlib, tensorflow\n",
            "Successfully installed keras-2.15.0 matplotlib-3.9.1 pandas-2.0.3 scikit-learn-1.5.1 tensorflow-2.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "pandas",
                  "tensorflow"
                ]
              },
              "id": "74d43b2cec6144cfb7ec1f582f2947d1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV # Import GridSearchCV here\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the dataset as a Pandas DataFrame\n",
        "path_to_csv = '/content/sample_data/Sentiment (3) (2).csv'\n",
        "dataset = pd.read_csv(path_to_csv, header=0)\n",
        "\n",
        "# Select only the necessary columns 'text' and 'sentiment'\n",
        "mask = dataset.columns.isin(['text', 'sentiment'])\n",
        "data = dataset.loc[:, mask]\n",
        "\n",
        "# Keeping only the necessary columns\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))\n",
        "\n",
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ') # Removing Retweets\n",
        "\n",
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ') # Maximum words is 2000 to tokenize sentence\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values) # Taking values to feature matrix\n",
        "X = pad_sequences(X) # Padding the feature matrix\n",
        "\n",
        "embed_dim = 128 # Dimension of the Embedded layer\n",
        "lstm_out = 196 # Long short-term memory (LSTM) layer neurons\n",
        "\n",
        "def createmodel():\n",
        "    model = Sequential() # Sequential Neural Network\n",
        "    model.add(Embedding(max_features, embed_dim, input_length = X.shape[1])) # input dimension 2000 Neurons, output dimension 128 Neurons\n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)) # Drop out 20%, 196 output Neurons, recurrent dropout 20%\n",
        "    model.add(Dense(3, activation='softmax')) # 3 output neurons[positive, Neutral, Negative], softmax as activation\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy']) # Compiling the model\n",
        "    return model\n",
        "\n",
        "labelencoder = LabelEncoder() # Applying label Encoding on the label matrix\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment']) # Fitting the model\n",
        "y = to_categorical(integer_encoded)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42) # 67% training data, 33% test data split\n",
        "\n",
        "batch_size = 32 # Batch size 32\n",
        "model = createmodel() # Function call to Sequential Neural Network\n",
        "model.fit(X_train, Y_train, epochs=1, batch_size=batch_size, verbose=2) # verbose the higher, the more messages\n",
        "score, acc = model.evaluate(X_test, Y_test, verbose=2, batch_size=batch_size) # evaluating the model\n",
        "print(score)\n",
        "print(acc)\n",
        "print(model.metrics_names) # metrics of the model\n",
        "print(integer_encoded)\n",
        "print(data['sentiment'])\n",
        "\n",
        "# Predicting on the text data\n",
        "sentence = ['A lot of good things are happening. We are respected again throughout the world, and that is a great thing.@realDonaldTrump']\n",
        "sentence = tokenizer.texts_to_sequences(sentence) # Tokenizing the sentence\n",
        "sentence = pad_sequences(sentence, maxlen=X.shape[1], dtype='int32', value=0) # Padding the sentence\n",
        "sentiment_probs = model.predict(sentence, batch_size=1, verbose=2)[0] # Predicting the sentence text\n",
        "sentiment = np.argmax(sentiment_probs)\n",
        "\n",
        "print(sentiment_probs)\n",
        "if sentiment == 0:\n",
        "    print(\"Neutral\")\n",
        "elif sentiment == 1:\n",
        "    print(\"Negative\")\n",
        "else:\n",
        "    print(\"Positive\")\n",
        "\n",
        "# Custom wrapper for Keras model\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class CustomKerasClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, build_fn=None, epochs=1, batch_size=32, verbose=1, **sk_params):\n",
        "        self.build_fn = build_fn\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.verbose = verbose\n",
        "        self.sk_params = sk_params\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y, **kwargs):\n",
        "        self.model = self.build_fn()\n",
        "        return self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose, **kwargs)\n",
        "\n",
        "    def predict(self, X, **kwargs):\n",
        "        return self.model.predict(X, **kwargs)\n",
        "\n",
        "    def predict_proba(self, X, **kwargs):\n",
        "        return self.model.predict(X, **kwargs)\n",
        "\n",
        "    def score(self, X, y, **kwargs):\n",
        "        _, accuracy = self.model.evaluate(X, y, verbose=0)\n",
        "        return accuracy\n",
        "\n",
        "# Use the custom Keras classifier\n",
        "model = CustomKerasClassifier(build_fn=createmodel, verbose=2)\n",
        "batch_size = [10, 20, 40]\n",
        "epochs = [1, 2]\n",
        "param_grid = {'batch_size': batch_size, 'epochs': epochs}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_train, Y_train)\n",
        "\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caJyiQ1P6O_2",
        "outputId": "9f31c5bc-fd31-491c-ae42-96ba24753ebf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-29e7784194f1>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].apply(lambda x: x.lower())\n",
            "<ipython-input-3-29e7784194f1>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 - 54s - loss: 0.8286 - accuracy: 0.6402 - 54s/epoch - 185ms/step\n",
            "144/144 - 3s - loss: 0.7557 - accuracy: 0.6747 - 3s/epoch - 24ms/step\n",
            "0.7557296752929688\n",
            "0.6747487783432007\n",
            "['loss', 'accuracy']\n",
            "[1 2 1 ... 2 0 2]\n",
            "0         Neutral\n",
            "1        Positive\n",
            "2         Neutral\n",
            "3        Positive\n",
            "4        Positive\n",
            "           ...   \n",
            "13866    Negative\n",
            "13867    Positive\n",
            "13868    Positive\n",
            "13869    Negative\n",
            "13870    Positive\n",
            "Name: sentiment, Length: 13871, dtype: object\n",
            "1/1 - 0s - 270ms/epoch - 270ms/step\n",
            "[0.65052605 0.13521926 0.21425472]\n",
            "Neutral\n",
            "744/744 - 104s - loss: 0.8231 - accuracy: 0.6527 - 104s/epoch - 140ms/step\n",
            "744/744 - 103s - loss: 0.8153 - accuracy: 0.6536 - 103s/epoch - 138ms/step\n",
            "744/744 - 110s - loss: 0.8244 - accuracy: 0.6430 - 110s/epoch - 148ms/step\n",
            "744/744 - 107s - loss: 0.8285 - accuracy: 0.6460 - 107s/epoch - 143ms/step\n",
            "744/744 - 104s - loss: 0.8198 - accuracy: 0.6477 - 104s/epoch - 140ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 108s - loss: 0.8231 - accuracy: 0.6472 - 108s/epoch - 145ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 105s - loss: 0.6746 - accuracy: 0.7112 - 105s/epoch - 141ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 110s - loss: 0.8176 - accuracy: 0.6523 - 110s/epoch - 148ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 100s - loss: 0.6809 - accuracy: 0.7103 - 100s/epoch - 135ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 102s - loss: 0.8207 - accuracy: 0.6457 - 102s/epoch - 137ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 101s - loss: 0.6781 - accuracy: 0.7146 - 101s/epoch - 136ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 109s - loss: 0.8297 - accuracy: 0.6461 - 109s/epoch - 146ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 105s - loss: 0.6814 - accuracy: 0.7077 - 105s/epoch - 142ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 106s - loss: 0.8216 - accuracy: 0.6425 - 106s/epoch - 142ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 102s - loss: 0.6714 - accuracy: 0.7089 - 102s/epoch - 137ms/step\n",
            "372/372 - 59s - loss: 0.8324 - accuracy: 0.6445 - 59s/epoch - 158ms/step\n",
            "372/372 - 63s - loss: 0.8277 - accuracy: 0.6457 - 63s/epoch - 168ms/step\n",
            "372/372 - 62s - loss: 0.8342 - accuracy: 0.6412 - 62s/epoch - 166ms/step\n",
            "372/372 - 59s - loss: 0.8420 - accuracy: 0.6409 - 59s/epoch - 159ms/step\n",
            "372/372 - 59s - loss: 0.8271 - accuracy: 0.6418 - 59s/epoch - 158ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 67s - loss: 0.8358 - accuracy: 0.6426 - 67s/epoch - 180ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 59s - loss: 0.6806 - accuracy: 0.7109 - 59s/epoch - 158ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 62s - loss: 0.8337 - accuracy: 0.6395 - 62s/epoch - 166ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 56s - loss: 0.6837 - accuracy: 0.7076 - 56s/epoch - 151ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 60s - loss: 0.8330 - accuracy: 0.6412 - 60s/epoch - 162ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 55s - loss: 0.6813 - accuracy: 0.7131 - 55s/epoch - 149ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 63s - loss: 0.8263 - accuracy: 0.6430 - 63s/epoch - 168ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 60s - loss: 0.6762 - accuracy: 0.7130 - 60s/epoch - 161ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 61s - loss: 0.8249 - accuracy: 0.6370 - 61s/epoch - 163ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 58s - loss: 0.6711 - accuracy: 0.7147 - 58s/epoch - 157ms/step\n",
            "186/186 - 39s - loss: 0.8417 - accuracy: 0.6341 - 39s/epoch - 207ms/step\n",
            "186/186 - 41s - loss: 0.8467 - accuracy: 0.6384 - 41s/epoch - 219ms/step\n",
            "186/186 - 40s - loss: 0.8501 - accuracy: 0.6344 - 40s/epoch - 215ms/step\n",
            "186/186 - 40s - loss: 0.8404 - accuracy: 0.6344 - 40s/epoch - 218ms/step\n",
            "186/186 - 40s - loss: 0.8411 - accuracy: 0.6401 - 40s/epoch - 213ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 39s - loss: 0.8473 - accuracy: 0.6403 - 39s/epoch - 210ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 35s - loss: 0.6873 - accuracy: 0.7020 - 35s/epoch - 188ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 39s - loss: 0.8414 - accuracy: 0.6427 - 39s/epoch - 207ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 35s - loss: 0.6902 - accuracy: 0.7062 - 35s/epoch - 190ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 41s - loss: 0.8450 - accuracy: 0.6317 - 41s/epoch - 219ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 34s - loss: 0.6908 - accuracy: 0.7037 - 34s/epoch - 184ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 41s - loss: 0.8431 - accuracy: 0.6351 - 41s/epoch - 218ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 36s - loss: 0.6854 - accuracy: 0.7080 - 36s/epoch - 195ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 39s - loss: 0.8310 - accuracy: 0.6417 - 39s/epoch - 212ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 34s - loss: 0.6868 - accuracy: 0.7037 - 34s/epoch - 182ms/step\n",
            "Epoch 1/2\n",
            "233/233 - 48s - loss: 0.8337 - accuracy: 0.6396 - 48s/epoch - 207ms/step\n",
            "Epoch 2/2\n",
            "233/233 - 44s - loss: 0.6792 - accuracy: 0.7114 - 44s/epoch - 190ms/step\n",
            "Best: 0.679974 using {'batch_size': 40, 'epochs': 2}\n"
          ]
        }
      ]
    }
  ]
}